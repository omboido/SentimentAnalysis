{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos usando SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook, utilizaremos uma abordagem diferente para analisar sentimentos. Aqui utilizaremos um léxico de sentimentos que define, para cada palavra, um índice de positividade, negatividade e objetividade (neutralidade). Utilizaremos o SentiWordNet para tal tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos carregar a base de teste dos reviews de filmes do IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = []\n",
    "for line in open('../Exercício 1/data/full_test.txt', 'r', encoding=\"utf8\"):\n",
    "    reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos nossos rótulos para essa base de dados. Como vimos, para essa base, os primeiros 12500 reviews são positivos, o resto é negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tratar a nossa base, removendo pontuação e tags HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o processo de tokenização do NLTK para separar os reviews por palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for text in reviews_test_clean:\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tokens.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos analisando cada palavra, temos que remover as stopwords dos reviews. Stopwords geralmente possuem sentimento neutro (objetivo), assim, a remoção facilita na hora de analisar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filter_tokens = []\n",
    "for t in tokens:\n",
    "    filter_tokens.append([w for w in t if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos recuperar os índices de cada palavra, criando uma tupla contendo os índices positivos, negativos e de objetividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\MM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for t in filter_tokens:\n",
    "    synsets = [lesk(t, w) for w in t]\n",
    "    sents = []\n",
    "    synsets = list(filter(None, synsets))\n",
    "    for s in synsets:\n",
    "        senti_ss = swn.senti_synset(s.name())\n",
    "        sents.append((senti_ss.pos_score(), senti_ss.neg_score(), senti_ss.obj_score()))\n",
    "    scores.append(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui fazemos a classificação para cada review. Para isso, verificamos qual índice é maior e contamos o número de palavras com índice positivo maior e o número de palavras com índice negativo maior. Ignoramos as palavras com índice de objetividade maior por serem neutras. Após isso, calculamos a razão de índices positivos por negativos e a razão inversa (negativos por positivos). A maior razão indica a classe do review.\n",
    "\n",
    "Crie um código que:\n",
    "\n",
    "* Conte palavras positivas (índice positivo maior que negativo e objetivo)\n",
    "* Conte palavras negativas (índice negativo maior que positivo e objetivo)\n",
    "* Ignore palavras neutras (índice objetivo maior que positivo e negativo)\n",
    "* Calcule a razão positiva (contagem positiva dividido pela contagem negativa)\n",
    "* Calcule a razão negativa (contagem negativa dividido pela contagem positiva)\n",
    "* Decida a classe: 1 (positivo - razão pos > razão neg), 0 (negativo - razão neg > razão pos)\n",
    "* Adicionar a classe na lista classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "for sc in scores:\n",
    "    c_pos = 0\n",
    "    c_neg = 0\n",
    "    c_obj = 0\n",
    "    for s in sc:\n",
    "        if s[0] > s[1] and s[0] > s[2]:\n",
    "            c_pos+=1\n",
    "        if s[1] > s[0] and s[1] > s[2]:\n",
    "            c_neg+=1\n",
    "        if s[2] > s[0] and s[2] > s[1]:\n",
    "            c_obj+=1\n",
    "    \n",
    "    #calculo da razão com smoothing (add-one)\n",
    "    ratio_pos = (c_pos + 1) / (c_neg + 1)\n",
    "    ratio_neg = (c_neg + 1) / (c_pos + 1)\n",
    "    \n",
    "    if ratio_pos > ratio_neg:\n",
    "        classes.append(1)\n",
    "    else:\n",
    "        classes.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quão preciso é nossa classificação? Vamos utilizar as classes reais dos reviews para calcular a acurácia.\n",
    "Dica: a acurácia é em torno de 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.65652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Complete a linha abaixo\n",
    "accuracy = accuracy_score(y_test, classes)\n",
    "\n",
    "print (\"Accuracy : %s\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
